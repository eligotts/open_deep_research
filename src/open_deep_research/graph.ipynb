{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from langgraph.types import interrupt, Command\n",
    "\n",
    "from src.open_deep_research.newsletter_graph import builder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entry_worker': {'execution_plan': ExecutionPlan(items=[PlanReconsiderationItem(id='initial_plan_creation', description='Create the initial execution plan for the newsletter generation process', status=<Status.PENDING: 'pending'>, output='', dependencies='No dependencies - this is the starting point', reason='Initial plan creation to establish the newsletter generation workflow', guiding_questions=['What are the core research topics needed?', 'When should template updates occur?', 'What dependencies exist between sections?'], proposed_changes='')])}}\n",
      "\n",
      "\n",
      "\n",
      "Creating OpenAI compatible model for ExecutionPlan\n",
      "Processing field items: typing.List[typing.Union[src.open_deep_research.newsletter_state.ResearchItem, src.open_deep_research.newsletter_state.PlanReconsiderationItem, src.open_deep_research.newsletter_state.TemplateBuilderItem]]\n",
      "Created new model: OpenAIExecutionPlan with fields: ['items']\n",
      "\n",
      "Converting ExecutionPlan to OpenAI schema\n",
      "\n",
      "Creating OpenAI compatible model for ExecutionPlan\n",
      "Processing field items: typing.List[typing.Union[src.open_deep_research.newsletter_state.ResearchItem, src.open_deep_research.newsletter_state.PlanReconsiderationItem, src.open_deep_research.newsletter_state.TemplateBuilderItem]]\n",
      "Created new model: OpenAIExecutionPlan with fields: ['items']\n",
      "Model data without defaults: {'items': [{'id': 'research_fireworks_1', 'description': 'Investigate the current state, technological advances, and market positioning of Fireworks in the AI inference market.', 'research_goal': \"Collect comprehensive data on Fireworks' product offerings, technological innovations, market partnerships, and competitive positioning within the AI inference market.\", 'important_context': 'Focus on how Fireworks differentiates itself in an emerging and competitive inference market with an emphasis on its unique technology and strategies.', 'desired_output': \"A detailed report summarizing key insights, data points, and analysis that can be integrated into the newsletter's company-specific section.\"}, {'id': 'research_togetherai_1', 'description': \"Analyze Together.ai's role and strategy in the AI inference market, including competitor analysis and potential future trends.\", 'research_goal': \"Investigate Together.ai's business model, strategic initiatives, and technological edge in the AI inference space to understand its market positioning.\", 'important_context': \"Assess Together.ai's collaborations, product innovations, and market strategies compared to other players in the AI inference ecosystem.\", 'desired_output': 'A concise summary outlining the strategic position and future outlook of Together.ai that can be used to inform a section of the newsletter.'}, {'id': 'research_groq_1', 'description': \"Research Groq's contributions and technological innovations in the AI inference market, assessing their competitive advantages.\", 'research_goal': \"Gather detailed information on Groq's hardware and software advancements, and analyze their impact on performance benchmarks in AI inference.\", 'important_context': \"Focus on Groq's innovative approach to AI inference acceleration and its potential influence on market dynamics.\", 'desired_output': 'An analytical report focusing on Groq’s technology and market impact, providing key insights for the newsletter’s technical analysis section.'}, {'id': 'reconsider_phase_1', 'description': 'Review the initial research findings and adjust the newsletter plan based on emerging insights from the three company research reports.', 'dependencies': 'Depends on outputs of research_fireworks_1, research_togetherai_1, research_groq_1. Required because the overall narrative and structure of the newsletter should be refined after understanding each company’s impact in the market.', 'reason': 'Ensure that the newsletter narrative remains cohesive and that research findings are accurately reflected in the editorial structure.', 'guiding_questions': ['Do the research insights suggest a dominant trend in the AI inference market?', 'How should the newsletter balance technical detail with market overview?', 'Are there any gaps or emerging topics that should be addressed?'], 'proposed_changes': 'Adjust section focus and narrative structure based on the comparative analysis of Fireworks, Together.ai, and Groq.'}, {'id': 'template_newsletter_1', 'description': 'Design and build the newsletter template integrating the research and reconsideration outputs.', 'dependencies': \"Depends on outputs of research_fireworks_1, research_togetherai_1, research_groq_1, and reconsider_phase_1. Required because the research insights and reconsideration insights will inform the newsletter's structure.\", 'template_goal': 'Develop a clear and engaging newsletter layout that includes an introduction, market overview, individual company analyses, and a conclusive insight section.', 'constraints': 'Ensure the template is flexible for digital distribution, uses clear headings, and highlights key data points. Content sections must seamlessly integrate textual analysis and data visualizations.', 'notes': 'The template should allow for future updates and modifications as additional insights or market changes occur.'}]}\n",
      "Final OpenAI schema: {'items': [{'id': 'research_fireworks_1', 'description': 'Investigate the current state, technological advances, and market positioning of Fireworks in the AI inference market.', 'status': <Status.PENDING: 'pending'>, 'output': '', 'dependencies': '', 'research_goal': \"Collect comprehensive data on Fireworks' product offerings, technological innovations, market partnerships, and competitive positioning within the AI inference market.\", 'effort': <EffortLevel.MEDIUM: 'medium'>, 'important_context': 'Focus on how Fireworks differentiates itself in an emerging and competitive inference market with an emphasis on its unique technology and strategies.', 'desired_output': \"A detailed report summarizing key insights, data points, and analysis that can be integrated into the newsletter's company-specific section.\"}, {'id': 'research_togetherai_1', 'description': \"Analyze Together.ai's role and strategy in the AI inference market, including competitor analysis and potential future trends.\", 'status': <Status.PENDING: 'pending'>, 'output': '', 'dependencies': '', 'research_goal': \"Investigate Together.ai's business model, strategic initiatives, and technological edge in the AI inference space to understand its market positioning.\", 'effort': <EffortLevel.MEDIUM: 'medium'>, 'important_context': \"Assess Together.ai's collaborations, product innovations, and market strategies compared to other players in the AI inference ecosystem.\", 'desired_output': 'A concise summary outlining the strategic position and future outlook of Together.ai that can be used to inform a section of the newsletter.'}, {'id': 'research_groq_1', 'description': \"Research Groq's contributions and technological innovations in the AI inference market, assessing their competitive advantages.\", 'status': <Status.PENDING: 'pending'>, 'output': '', 'dependencies': '', 'research_goal': \"Gather detailed information on Groq's hardware and software advancements, and analyze their impact on performance benchmarks in AI inference.\", 'effort': <EffortLevel.MEDIUM: 'medium'>, 'important_context': \"Focus on Groq's innovative approach to AI inference acceleration and its potential influence on market dynamics.\", 'desired_output': 'An analytical report focusing on Groq’s technology and market impact, providing key insights for the newsletter’s technical analysis section.'}, {'id': 'reconsider_phase_1', 'description': 'Review the initial research findings and adjust the newsletter plan based on emerging insights from the three company research reports.', 'status': <Status.PENDING: 'pending'>, 'output': '', 'dependencies': 'Depends on outputs of research_fireworks_1, research_togetherai_1, research_groq_1. Required because the overall narrative and structure of the newsletter should be refined after understanding each company’s impact in the market.', 'reason': 'Ensure that the newsletter narrative remains cohesive and that research findings are accurately reflected in the editorial structure.', 'guiding_questions': ['Do the research insights suggest a dominant trend in the AI inference market?', 'How should the newsletter balance technical detail with market overview?', 'Are there any gaps or emerging topics that should be addressed?'], 'proposed_changes': 'Adjust section focus and narrative structure based on the comparative analysis of Fireworks, Together.ai, and Groq.'}, {'id': 'template_newsletter_1', 'description': 'Design and build the newsletter template integrating the research and reconsideration outputs.', 'status': <Status.PENDING: 'pending'>, 'output': '', 'dependencies': \"Depends on outputs of research_fireworks_1, research_togetherai_1, research_groq_1, and reconsider_phase_1. Required because the research insights and reconsideration insights will inform the newsletter's structure.\", 'template_goal': 'Develop a clear and engaging newsletter layout that includes an introduction, market overview, individual company analyses, and a conclusive insight section.', 'constraints': 'Ensure the template is flexible for digital distribution, uses clear headings, and highlights key data points. Content sections must seamlessly integrate textual analysis and data visualizations.', 'notes': 'The template should allow for future updates and modifications as additional insights or market changes occur.'}]}\n",
      "\n",
      "Converting OpenAI response back to ExecutionPlan\n",
      "Input data: {'items': [{'id': 'research_fireworks_1', 'description': 'Investigate the current state, technological advances, and market positioning of Fireworks in the AI inference market.', 'status': <Status.PENDING: 'pending'>, 'output': '', 'dependencies': '', 'research_goal': \"Collect comprehensive data on Fireworks' product offerings, technological innovations, market partnerships, and competitive positioning within the AI inference market.\", 'effort': <EffortLevel.MEDIUM: 'medium'>, 'important_context': 'Focus on how Fireworks differentiates itself in an emerging and competitive inference market with an emphasis on its unique technology and strategies.', 'desired_output': \"A detailed report summarizing key insights, data points, and analysis that can be integrated into the newsletter's company-specific section.\"}, {'id': 'research_togetherai_1', 'description': \"Analyze Together.ai's role and strategy in the AI inference market, including competitor analysis and potential future trends.\", 'status': <Status.PENDING: 'pending'>, 'output': '', 'dependencies': '', 'research_goal': \"Investigate Together.ai's business model, strategic initiatives, and technological edge in the AI inference space to understand its market positioning.\", 'effort': <EffortLevel.MEDIUM: 'medium'>, 'important_context': \"Assess Together.ai's collaborations, product innovations, and market strategies compared to other players in the AI inference ecosystem.\", 'desired_output': 'A concise summary outlining the strategic position and future outlook of Together.ai that can be used to inform a section of the newsletter.'}, {'id': 'research_groq_1', 'description': \"Research Groq's contributions and technological innovations in the AI inference market, assessing their competitive advantages.\", 'status': <Status.PENDING: 'pending'>, 'output': '', 'dependencies': '', 'research_goal': \"Gather detailed information on Groq's hardware and software advancements, and analyze their impact on performance benchmarks in AI inference.\", 'effort': <EffortLevel.MEDIUM: 'medium'>, 'important_context': \"Focus on Groq's innovative approach to AI inference acceleration and its potential influence on market dynamics.\", 'desired_output': 'An analytical report focusing on Groq’s technology and market impact, providing key insights for the newsletter’s technical analysis section.'}, {'id': 'reconsider_phase_1', 'description': 'Review the initial research findings and adjust the newsletter plan based on emerging insights from the three company research reports.', 'status': <Status.PENDING: 'pending'>, 'output': '', 'dependencies': 'Depends on outputs of research_fireworks_1, research_togetherai_1, research_groq_1. Required because the overall narrative and structure of the newsletter should be refined after understanding each company’s impact in the market.', 'reason': 'Ensure that the newsletter narrative remains cohesive and that research findings are accurately reflected in the editorial structure.', 'guiding_questions': ['Do the research insights suggest a dominant trend in the AI inference market?', 'How should the newsletter balance technical detail with market overview?', 'Are there any gaps or emerging topics that should be addressed?'], 'proposed_changes': 'Adjust section focus and narrative structure based on the comparative analysis of Fireworks, Together.ai, and Groq.'}, {'id': 'template_newsletter_1', 'description': 'Design and build the newsletter template integrating the research and reconsideration outputs.', 'status': <Status.PENDING: 'pending'>, 'output': '', 'dependencies': \"Depends on outputs of research_fireworks_1, research_togetherai_1, research_groq_1, and reconsider_phase_1. Required because the research insights and reconsideration insights will inform the newsletter's structure.\", 'template_goal': 'Develop a clear and engaging newsletter layout that includes an introduction, market overview, individual company analyses, and a conclusive insight section.', 'constraints': 'Ensure the template is flexible for digital distribution, uses clear headings, and highlights key data points. Content sections must seamlessly integrate textual analysis and data visualizations.', 'notes': 'The template should allow for future updates and modifications as additional insights or market changes occur.'}]}\n",
      "Converted to internal model with defaults: {'items': [{'id': 'research_fireworks_1', 'description': 'Investigate the current state, technological advances, and market positioning of Fireworks in the AI inference market.', 'status': <Status.PENDING: 'pending'>, 'output': '', 'dependencies': '', 'research_goal': \"Collect comprehensive data on Fireworks' product offerings, technological innovations, market partnerships, and competitive positioning within the AI inference market.\", 'effort': <EffortLevel.MEDIUM: 'medium'>, 'important_context': 'Focus on how Fireworks differentiates itself in an emerging and competitive inference market with an emphasis on its unique technology and strategies.', 'desired_output': \"A detailed report summarizing key insights, data points, and analysis that can be integrated into the newsletter's company-specific section.\"}, {'id': 'research_togetherai_1', 'description': \"Analyze Together.ai's role and strategy in the AI inference market, including competitor analysis and potential future trends.\", 'status': <Status.PENDING: 'pending'>, 'output': '', 'dependencies': '', 'research_goal': \"Investigate Together.ai's business model, strategic initiatives, and technological edge in the AI inference space to understand its market positioning.\", 'effort': <EffortLevel.MEDIUM: 'medium'>, 'important_context': \"Assess Together.ai's collaborations, product innovations, and market strategies compared to other players in the AI inference ecosystem.\", 'desired_output': 'A concise summary outlining the strategic position and future outlook of Together.ai that can be used to inform a section of the newsletter.'}, {'id': 'research_groq_1', 'description': \"Research Groq's contributions and technological innovations in the AI inference market, assessing their competitive advantages.\", 'status': <Status.PENDING: 'pending'>, 'output': '', 'dependencies': '', 'research_goal': \"Gather detailed information on Groq's hardware and software advancements, and analyze their impact on performance benchmarks in AI inference.\", 'effort': <EffortLevel.MEDIUM: 'medium'>, 'important_context': \"Focus on Groq's innovative approach to AI inference acceleration and its potential influence on market dynamics.\", 'desired_output': 'An analytical report focusing on Groq’s technology and market impact, providing key insights for the newsletter’s technical analysis section.'}, {'id': 'reconsider_phase_1', 'description': 'Review the initial research findings and adjust the newsletter plan based on emerging insights from the three company research reports.', 'status': <Status.PENDING: 'pending'>, 'output': '', 'dependencies': 'Depends on outputs of research_fireworks_1, research_togetherai_1, research_groq_1. Required because the overall narrative and structure of the newsletter should be refined after understanding each company’s impact in the market.', 'reason': 'Ensure that the newsletter narrative remains cohesive and that research findings are accurately reflected in the editorial structure.', 'guiding_questions': ['Do the research insights suggest a dominant trend in the AI inference market?', 'How should the newsletter balance technical detail with market overview?', 'Are there any gaps or emerging topics that should be addressed?'], 'proposed_changes': 'Adjust section focus and narrative structure based on the comparative analysis of Fireworks, Together.ai, and Groq.'}, {'id': 'template_newsletter_1', 'description': 'Design and build the newsletter template integrating the research and reconsideration outputs.', 'status': <Status.PENDING: 'pending'>, 'output': '', 'dependencies': \"Depends on outputs of research_fireworks_1, research_togetherai_1, research_groq_1, and reconsider_phase_1. Required because the research insights and reconsideration insights will inform the newsletter's structure.\", 'template_goal': 'Develop a clear and engaging newsletter layout that includes an introduction, market overview, individual company analyses, and a conclusive insight section.', 'constraints': 'Ensure the template is flexible for digital distribution, uses clear headings, and highlights key data points. Content sections must seamlessly integrate textual analysis and data visualizations.', 'notes': 'The template should allow for future updates and modifications as additional insights or market changes occur.'}]}\n",
      "{'execution_plan_builder': {'execution_plan': ExecutionPlan(items=[ResearchItem(id='research_fireworks_1', description='Investigate the current state, technological advances, and market positioning of Fireworks in the AI inference market.', status=<Status.PENDING: 'pending'>, output='', dependencies='', research_goal=\"Collect comprehensive data on Fireworks' product offerings, technological innovations, market partnerships, and competitive positioning within the AI inference market.\", effort=<EffortLevel.MEDIUM: 'medium'>, important_context='Focus on how Fireworks differentiates itself in an emerging and competitive inference market with an emphasis on its unique technology and strategies.', desired_output=\"A detailed report summarizing key insights, data points, and analysis that can be integrated into the newsletter's company-specific section.\"), ResearchItem(id='research_togetherai_1', description=\"Analyze Together.ai's role and strategy in the AI inference market, including competitor analysis and potential future trends.\", status=<Status.PENDING: 'pending'>, output='', dependencies='', research_goal=\"Investigate Together.ai's business model, strategic initiatives, and technological edge in the AI inference space to understand its market positioning.\", effort=<EffortLevel.MEDIUM: 'medium'>, important_context=\"Assess Together.ai's collaborations, product innovations, and market strategies compared to other players in the AI inference ecosystem.\", desired_output='A concise summary outlining the strategic position and future outlook of Together.ai that can be used to inform a section of the newsletter.'), ResearchItem(id='research_groq_1', description=\"Research Groq's contributions and technological innovations in the AI inference market, assessing their competitive advantages.\", status=<Status.PENDING: 'pending'>, output='', dependencies='', research_goal=\"Gather detailed information on Groq's hardware and software advancements, and analyze their impact on performance benchmarks in AI inference.\", effort=<EffortLevel.MEDIUM: 'medium'>, important_context=\"Focus on Groq's innovative approach to AI inference acceleration and its potential influence on market dynamics.\", desired_output='An analytical report focusing on Groq’s technology and market impact, providing key insights for the newsletter’s technical analysis section.'), PlanReconsiderationItem(id='reconsider_phase_1', description='Review the initial research findings and adjust the newsletter plan based on emerging insights from the three company research reports.', status=<Status.PENDING: 'pending'>, output='', dependencies='Depends on outputs of research_fireworks_1, research_togetherai_1, research_groq_1. Required because the overall narrative and structure of the newsletter should be refined after understanding each company’s impact in the market.', reason='Ensure that the newsletter narrative remains cohesive and that research findings are accurately reflected in the editorial structure.', guiding_questions=['Do the research insights suggest a dominant trend in the AI inference market?', 'How should the newsletter balance technical detail with market overview?', 'Are there any gaps or emerging topics that should be addressed?'], proposed_changes='Adjust section focus and narrative structure based on the comparative analysis of Fireworks, Together.ai, and Groq.'), TemplateBuilderItem(id='template_newsletter_1', description='Design and build the newsletter template integrating the research and reconsideration outputs.', status=<Status.PENDING: 'pending'>, output='', dependencies=\"Depends on outputs of research_fireworks_1, research_togetherai_1, research_groq_1, and reconsider_phase_1. Required because the research insights and reconsideration insights will inform the newsletter's structure.\", template_goal='Develop a clear and engaging newsletter layout that includes an introduction, market overview, individual company analyses, and a conclusive insight section.', constraints='Ensure the template is flexible for digital distribution, uses clear headings, and highlights key data points. Content sections must seamlessly integrate textual analysis and data visualizations.', notes='The template should allow for future updates and modifications as additional insights or market changes occur.')]), 'completed_items': [PlanReconsiderationItem(id='initial_plan_creation', description='Create the initial execution plan for the newsletter generation process', status=<Status.COMPLETED: 'completed'>, output=\"Plan created\\nTotal items: 5\\nItems breakdown:\\n- research_fireworks_1: Investigate the current state, technological advances, and market positioning of Fireworks in the AI inference market. (ResearchItem)\\n- research_togetherai_1: Analyze Together.ai's role and strategy in the AI inference market, including competitor analysis and potential future trends. (ResearchItem)\\n- research_groq_1: Research Groq's contributions and technological innovations in the AI inference market, assessing their competitive advantages. (ResearchItem)\\n- reconsider_phase_1: Review the initial research findings and adjust the newsletter plan based on emerging insights from the three company research reports. (PlanReconsiderationItem)\\n- template_newsletter_1: Design and build the newsletter template integrating the research and reconsideration outputs. (TemplateBuilderItem)\", dependencies='No dependencies - this is the starting point', reason='Initial plan creation to establish the newsletter generation workflow', guiding_questions=['What are the core research topics needed?', 'When should template updates occur?', 'What dependencies exist between sections?'], proposed_changes='')]}}\n",
      "\n",
      "\n",
      "{'execution_orchestrator': {'execution_plan': ExecutionPlan(items=[ResearchItem(id='research_togetherai_1', description=\"Analyze Together.ai's role and strategy in the AI inference market, including competitor analysis and potential future trends.\", status=<Status.PENDING: 'pending'>, output='', dependencies='', research_goal=\"Investigate Together.ai's business model, strategic initiatives, and technological edge in the AI inference space to understand its market positioning.\", effort=<EffortLevel.MEDIUM: 'medium'>, important_context=\"Assess Together.ai's collaborations, product innovations, and market strategies compared to other players in the AI inference ecosystem.\", desired_output='A concise summary outlining the strategic position and future outlook of Together.ai that can be used to inform a section of the newsletter.'), ResearchItem(id='research_groq_1', description=\"Research Groq's contributions and technological innovations in the AI inference market, assessing their competitive advantages.\", status=<Status.PENDING: 'pending'>, output='', dependencies='', research_goal=\"Gather detailed information on Groq's hardware and software advancements, and analyze their impact on performance benchmarks in AI inference.\", effort=<EffortLevel.MEDIUM: 'medium'>, important_context=\"Focus on Groq's innovative approach to AI inference acceleration and its potential influence on market dynamics.\", desired_output='An analytical report focusing on Groq’s technology and market impact, providing key insights for the newsletter’s technical analysis section.'), PlanReconsiderationItem(id='reconsider_phase_1', description='Review the initial research findings and adjust the newsletter plan based on emerging insights from the three company research reports.', status=<Status.PENDING: 'pending'>, output='', dependencies='Depends on outputs of research_fireworks_1, research_togetherai_1, research_groq_1. Required because the overall narrative and structure of the newsletter should be refined after understanding each company’s impact in the market.', reason='Ensure that the newsletter narrative remains cohesive and that research findings are accurately reflected in the editorial structure.', guiding_questions=['Do the research insights suggest a dominant trend in the AI inference market?', 'How should the newsletter balance technical detail with market overview?', 'Are there any gaps or emerging topics that should be addressed?'], proposed_changes='Adjust section focus and narrative structure based on the comparative analysis of Fireworks, Together.ai, and Groq.'), TemplateBuilderItem(id='template_newsletter_1', description='Design and build the newsletter template integrating the research and reconsideration outputs.', status=<Status.PENDING: 'pending'>, output='', dependencies=\"Depends on outputs of research_fireworks_1, research_togetherai_1, research_groq_1, and reconsider_phase_1. Required because the research insights and reconsideration insights will inform the newsletter's structure.\", template_goal='Develop a clear and engaging newsletter layout that includes an introduction, market overview, individual company analyses, and a conclusive insight section.', constraints='Ensure the template is flexible for digital distribution, uses clear headings, and highlights key data points. Content sections must seamlessly integrate textual analysis and data visualizations.', notes='The template should allow for future updates and modifications as additional insights or market changes occur.')])}}\n",
      "\n",
      "\n",
      "\n",
      "Creating OpenAI compatible model for Queries\n",
      "Processing field queries: typing.List[src.open_deep_research.newsletter_state.SearchQuery]\n",
      "Created new model: OpenAIQueries with fields: ['queries']\n",
      "\n",
      "Converting Queries to OpenAI schema\n",
      "\n",
      "Creating OpenAI compatible model for Queries\n",
      "Processing field queries: typing.List[src.open_deep_research.newsletter_state.SearchQuery]\n",
      "Created new model: OpenAIQueries with fields: ['queries']\n",
      "Model data without defaults: {'queries': [{'search_query': 'Fireworks AI inference market product offerings technological innovations market partnerships unique technology strategies 2022 2023 review'}, {'search_query': 'Fireworks competitive positioning in AI inference market analysis recent market partnerships and innovative product differentiation since 2022'}]}\n",
      "Final OpenAI schema: {'queries': [{'search_query': 'Fireworks AI inference market product offerings technological innovations market partnerships unique technology strategies 2022 2023 review'}, {'search_query': 'Fireworks competitive positioning in AI inference market analysis recent market partnerships and innovative product differentiation since 2022'}]}\n",
      "\n",
      "Converting OpenAI response back to Queries\n",
      "Input data: {'queries': [{'search_query': 'Fireworks AI inference market product offerings technological innovations market partnerships unique technology strategies 2022 2023 review'}, {'search_query': 'Fireworks competitive positioning in AI inference market analysis recent market partnerships and innovative product differentiation since 2022'}]}\n",
      "Converted to internal model with defaults: {'queries': [{'search_query': 'Fireworks AI inference market product offerings technological innovations market partnerships unique technology strategies 2022 2023 review'}, {'search_query': 'Fireworks competitive positioning in AI inference market analysis recent market partnerships and innovative product differentiation since 2022'}]}\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m topic \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOverview of the AI inference market with focus on Fireworks, Together.ai, Groq\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Run the graph until the interruption\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mastream({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m\"\u001b[39m:topic,}, thread, stream_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdates\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(event)\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/open_deep_research/.venv/lib/python3.11/site-packages/langgraph/pregel/__init__.py:2062\u001b[0m, in \u001b[0;36mPregel.astream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2056\u001b[0m \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   2057\u001b[0m \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[1;32m   2058\u001b[0m \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   2059\u001b[0m \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   2060\u001b[0m \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[1;32m   2061\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[0;32m-> 2062\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39matick(\n\u001b[1;32m   2063\u001b[0m         loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m   2064\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m   2065\u001b[0m         retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[1;32m   2066\u001b[0m         get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[1;32m   2067\u001b[0m     ):\n\u001b[1;32m   2068\u001b[0m         \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   2069\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m output():\n\u001b[1;32m   2070\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m o\n",
      "File \u001b[0;32m~/Documents/open_deep_research/.venv/lib/python3.11/site-packages/langgraph/pregel/runner.py:444\u001b[0m, in \u001b[0;36mPregelRunner.atick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    442\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m arun_with_retry(\n\u001b[1;32m    445\u001b[0m         t,\n\u001b[1;32m    446\u001b[0m         retry_policy,\n\u001b[1;32m    447\u001b[0m         stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_astream,\n\u001b[1;32m    448\u001b[0m         configurable\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    449\u001b[0m             CONFIG_KEY_SEND: partial(writer, t),\n\u001b[1;32m    450\u001b[0m             CONFIG_KEY_CALL: partial(call, t),\n\u001b[1;32m    451\u001b[0m         },\n\u001b[1;32m    452\u001b[0m     )\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Documents/open_deep_research/.venv/lib/python3.11/site-packages/langgraph/pregel/retry.py:128\u001b[0m, in \u001b[0;36marun_with_retry\u001b[0;34m(task, retry_policy, stream, configurable)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 128\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m task\u001b[38;5;241m.\u001b[39mproc\u001b[38;5;241m.\u001b[39mainvoke(task\u001b[38;5;241m.\u001b[39minput, config)\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    130\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[0;32m~/Documents/open_deep_research/.venv/lib/python3.11/site-packages/langgraph/utils/runnable.py:583\u001b[0m, in \u001b[0;36mRunnableSeq.ainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    579\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[1;32m    580\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    581\u001b[0m )\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 583\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m step\u001b[38;5;241m.\u001b[39mainvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m step\u001b[38;5;241m.\u001b[39mainvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/Documents/open_deep_research/.venv/lib/python3.11/site-packages/langgraph/pregel/__init__.py:2177\u001b[0m, in \u001b[0;36mPregel.ainvoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2176\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 2177\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mastream(\n\u001b[1;32m   2178\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   2179\u001b[0m     config,\n\u001b[1;32m   2180\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[1;32m   2181\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m   2182\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[1;32m   2183\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[1;32m   2184\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[1;32m   2185\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2186\u001b[0m ):\n\u001b[1;32m   2187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2188\u001b[0m         latest \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[0;32m~/Documents/open_deep_research/.venv/lib/python3.11/site-packages/langgraph/pregel/__init__.py:2062\u001b[0m, in \u001b[0;36mPregel.astream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2056\u001b[0m \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   2057\u001b[0m \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[1;32m   2058\u001b[0m \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   2059\u001b[0m \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   2060\u001b[0m \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[1;32m   2061\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[0;32m-> 2062\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39matick(\n\u001b[1;32m   2063\u001b[0m         loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m   2064\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m   2065\u001b[0m         retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[1;32m   2066\u001b[0m         get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[1;32m   2067\u001b[0m     ):\n\u001b[1;32m   2068\u001b[0m         \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   2069\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m output():\n\u001b[1;32m   2070\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m o\n",
      "File \u001b[0;32m~/Documents/open_deep_research/.venv/lib/python3.11/site-packages/langgraph/pregel/runner.py:444\u001b[0m, in \u001b[0;36mPregelRunner.atick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    442\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m arun_with_retry(\n\u001b[1;32m    445\u001b[0m         t,\n\u001b[1;32m    446\u001b[0m         retry_policy,\n\u001b[1;32m    447\u001b[0m         stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_astream,\n\u001b[1;32m    448\u001b[0m         configurable\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    449\u001b[0m             CONFIG_KEY_SEND: partial(writer, t),\n\u001b[1;32m    450\u001b[0m             CONFIG_KEY_CALL: partial(call, t),\n\u001b[1;32m    451\u001b[0m         },\n\u001b[1;32m    452\u001b[0m     )\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Documents/open_deep_research/.venv/lib/python3.11/site-packages/langgraph/pregel/retry.py:128\u001b[0m, in \u001b[0;36marun_with_retry\u001b[0;34m(task, retry_policy, stream, configurable)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 128\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m task\u001b[38;5;241m.\u001b[39mproc\u001b[38;5;241m.\u001b[39mainvoke(task\u001b[38;5;241m.\u001b[39minput, config)\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    130\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[0;32m~/Documents/open_deep_research/.venv/lib/python3.11/site-packages/langgraph/utils/runnable.py:583\u001b[0m, in \u001b[0;36mRunnableSeq.ainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    579\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[1;32m    580\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    581\u001b[0m )\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 583\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m step\u001b[38;5;241m.\u001b[39mainvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m step\u001b[38;5;241m.\u001b[39mainvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/Documents/open_deep_research/.venv/lib/python3.11/site-packages/langgraph/utils/runnable.py:371\u001b[0m, in \u001b[0;36mRunnableCallable.ainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ASYNCIO_ACCEPTS_CONTEXT:\n\u001b[1;32m    370\u001b[0m     coro \u001b[38;5;241m=\u001b[39m cast(Coroutine[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, Any], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m--> 371\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(coro, context\u001b[38;5;241m=\u001b[39mcontext)\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    373\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Documents/open_deep_research/src/open_deep_research/newsletter_graph.py:351\u001b[0m, in \u001b[0;36msearch_web\u001b[0;34m(state, config)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;66;03m# Search the web\u001b[39;00m\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m search_api \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtavily\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 351\u001b[0m         search_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m tavily_search_async(query_list)\n\u001b[1;32m    352\u001b[0m         source_str \u001b[38;5;241m=\u001b[39m deduplicate_and_format_sources(search_results, max_tokens_per_source\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m, include_raw_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m search_api \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mperplexity\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/open_deep_research/.venv/lib/python3.11/site-packages/langsmith/run_helpers.py:534\u001b[0m, in \u001b[0;36mtraceable.<locals>.decorator.<locals>.async_wrapper\u001b[0;34m(langsmith_extra, *args, **kwargs)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;66;03m# shield from cancellation, given we're catching all exceptions\u001b[39;00m\n\u001b[1;32m    531\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mshield(\n\u001b[1;32m    532\u001b[0m         aitertools\u001b[38;5;241m.\u001b[39maio_to_thread(_on_run_end, run_container, error\u001b[38;5;241m=\u001b[39me)\n\u001b[1;32m    533\u001b[0m     )\n\u001b[0;32m--> 534\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m aitertools\u001b[38;5;241m.\u001b[39maio_to_thread(\n\u001b[1;32m    536\u001b[0m     _on_run_end, run_container, outputs\u001b[38;5;241m=\u001b[39mfunction_result\n\u001b[1;32m    537\u001b[0m )\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function_result\n",
      "File \u001b[0;32m~/Documents/open_deep_research/.venv/lib/python3.11/site-packages/langsmith/run_helpers.py:520\u001b[0m, in \u001b[0;36mtraceable.<locals>.decorator.<locals>.async_wrapper\u001b[0;34m(langsmith_extra, *args, **kwargs)\u001b[0m\n\u001b[1;32m    518\u001b[0m fr_coro \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accepts_context:\n\u001b[0;32m--> 520\u001b[0m     function_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m    521\u001b[0m         fr_coro, context\u001b[38;5;241m=\u001b[39mrun_container[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    522\u001b[0m     )\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;66;03m# Python < 3.11\u001b[39;00m\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tracing_context(\n\u001b[1;32m    526\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mget_tracing_context(run_container[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    527\u001b[0m     ):\n",
      "File \u001b[0;32m~/Documents/open_deep_research/src/open_deep_research/utils.py:120\u001b[0m, in \u001b[0;36mtavily_search_async\u001b[0;34m(search_queries)\u001b[0m\n\u001b[1;32m    110\u001b[0m         search_tasks\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    111\u001b[0m             tavily_async_client\u001b[38;5;241m.\u001b[39msearch(\n\u001b[1;32m    112\u001b[0m                 query,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    116\u001b[0m             )\n\u001b[1;32m    117\u001b[0m         )\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# Execute all searches concurrently\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m search_docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39msearch_tasks)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m search_docs\n",
      "File \u001b[0;32m~/Documents/open_deep_research/.venv/lib/python3.11/site-packages/tavily/async_tavily.py:102\u001b[0m, in \u001b[0;36mAsyncTavilyClient.search\u001b[0;34m(self, query, search_depth, topic, days, max_results, include_domains, exclude_domains, include_answer, include_raw_content, include_images, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msearch\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     87\u001b[0m                  query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     88\u001b[0m                  search_depth: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbasic\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madvanced\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbasic\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     97\u001b[0m                  \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,  \u001b[38;5;66;03m# Accept custom arguments\u001b[39;00m\n\u001b[1;32m     98\u001b[0m                  ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m     99\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m    Combined search method. Set search_depth to either \"basic\" or \"advanced\".\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m     response_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_search(query,\n\u001b[1;32m    103\u001b[0m                                        search_depth\u001b[38;5;241m=\u001b[39msearch_depth,\n\u001b[1;32m    104\u001b[0m                                        topic\u001b[38;5;241m=\u001b[39mtopic,\n\u001b[1;32m    105\u001b[0m                                        days\u001b[38;5;241m=\u001b[39mdays,\n\u001b[1;32m    106\u001b[0m                                        max_results\u001b[38;5;241m=\u001b[39mmax_results,\n\u001b[1;32m    107\u001b[0m                                        include_domains\u001b[38;5;241m=\u001b[39minclude_domains,\n\u001b[1;32m    108\u001b[0m                                        exclude_domains\u001b[38;5;241m=\u001b[39mexclude_domains,\n\u001b[1;32m    109\u001b[0m                                        include_answer\u001b[38;5;241m=\u001b[39minclude_answer,\n\u001b[1;32m    110\u001b[0m                                        include_raw_content\u001b[38;5;241m=\u001b[39minclude_raw_content,\n\u001b[1;32m    111\u001b[0m                                        include_images\u001b[38;5;241m=\u001b[39minclude_images,\n\u001b[1;32m    112\u001b[0m                                        \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    113\u001b[0m                                        )\n\u001b[1;32m    115\u001b[0m     tavily_results \u001b[38;5;241m=\u001b[39m response_dict\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])\n\u001b[1;32m    117\u001b[0m     response_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tavily_results\n",
      "File \u001b[0;32m~/Documents/open_deep_research/.venv/lib/python3.11/site-packages/tavily/async_tavily.py:69\u001b[0m, in \u001b[0;36mAsyncTavilyClient._search\u001b[0;34m(self, query, search_depth, topic, days, max_results, include_domains, exclude_domains, include_answer, include_raw_content, include_images, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m     data\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_creator() \u001b[38;5;28;01mas\u001b[39;00m client:\n\u001b[0;32m---> 69\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m client\u001b[38;5;241m.\u001b[39mpost(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/search\u001b[39m\u001b[38;5;124m\"\u001b[39m, content\u001b[38;5;241m=\u001b[39mjson\u001b[38;5;241m.\u001b[39mdumps(data))\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/Documents/open_deep_research/.venv/lib/python3.11/site-packages/httpx/_client.py:1859\u001b[0m, in \u001b[0;36mAsyncClient.post\u001b[0;34m(self, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m   1838\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1839\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1840\u001b[0m     url: URL \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1852\u001b[0m     extensions: RequestExtensions \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1853\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Response:\n\u001b[1;32m   1854\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1855\u001b[0m \u001b[38;5;124;03m    Send a `POST` request.\u001b[39;00m\n\u001b[1;32m   1856\u001b[0m \n\u001b[1;32m   1857\u001b[0m \u001b[38;5;124;03m    **Parameters**: See `httpx.request`.\u001b[39;00m\n\u001b[1;32m   1858\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m   1860\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1861\u001b[0m         url,\n\u001b[1;32m   1862\u001b[0m         content\u001b[38;5;241m=\u001b[39mcontent,\n\u001b[1;32m   1863\u001b[0m         data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m   1864\u001b[0m         files\u001b[38;5;241m=\u001b[39mfiles,\n\u001b[1;32m   1865\u001b[0m         json\u001b[38;5;241m=\u001b[39mjson,\n\u001b[1;32m   1866\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m   1867\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   1868\u001b[0m         cookies\u001b[38;5;241m=\u001b[39mcookies,\n\u001b[1;32m   1869\u001b[0m         auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[1;32m   1870\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[1;32m   1871\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m   1872\u001b[0m         extensions\u001b[38;5;241m=\u001b[39mextensions,\n\u001b[1;32m   1873\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/open_deep_research/.venv/lib/python3.11/site-packages/httpx/_client.py:1540\u001b[0m, in \u001b[0;36mAsyncClient.request\u001b[0;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m   1525\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m   1527\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[1;32m   1528\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m   1529\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1538\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mextensions,\n\u001b[1;32m   1539\u001b[0m )\n\u001b[0;32m-> 1540\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(request, auth\u001b[38;5;241m=\u001b[39mauth, follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects)\n",
      "File \u001b[0;32m~/Documents/open_deep_research/.venv/lib/python3.11/site-packages/httpx/_client.py:1629\u001b[0m, in \u001b[0;36mAsyncClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m   1625\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m   1627\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m-> 1629\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_auth(\n\u001b[1;32m   1630\u001b[0m     request,\n\u001b[1;32m   1631\u001b[0m     auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[1;32m   1632\u001b[0m     follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[1;32m   1633\u001b[0m     history\u001b[38;5;241m=\u001b[39m[],\n\u001b[1;32m   1634\u001b[0m )\n\u001b[1;32m   1635\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1636\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/Documents/open_deep_research/.venv/lib/python3.11/site-packages/httpx/_client.py:1657\u001b[0m, in \u001b[0;36mAsyncClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m   1654\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m auth_flow\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__anext__\u001b[39m()\n\u001b[1;32m   1656\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1657\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_redirects(\n\u001b[1;32m   1658\u001b[0m         request,\n\u001b[1;32m   1659\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[1;32m   1660\u001b[0m         history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[1;32m   1661\u001b[0m     )\n\u001b[1;32m   1662\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1663\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/open_deep_research/.venv/lib/python3.11/site-packages/httpx/_client.py:1694\u001b[0m, in \u001b[0;36mAsyncClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m   1691\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   1692\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m hook(request)\n\u001b[0;32m-> 1694\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_single_request(request)\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1696\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/Documents/open_deep_research/.venv/lib/python3.11/site-packages/httpx/_client.py:1730\u001b[0m, in \u001b[0;36mAsyncClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1725\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1726\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an sync request with an AsyncClient instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1727\u001b[0m     )\n\u001b[1;32m   1729\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1730\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m transport\u001b[38;5;241m.\u001b[39mhandle_async_request(request)\n\u001b[1;32m   1732\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, AsyncByteStream)\n\u001b[1;32m   1733\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/Documents/open_deep_research/.venv/lib/python3.11/site-packages/httpx/_transports/default.py:394\u001b[0m, in \u001b[0;36mAsyncHTTPTransport.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    381\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    382\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    383\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    391\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    392\u001b[0m )\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 394\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_async_request(req)\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mAsyncIterable)\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    399\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    400\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    401\u001b[0m     stream\u001b[38;5;241m=\u001b[39mAsyncResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    402\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    403\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/open_deep_research/.venv/lib/python3.11/site-packages/httpcore/_async/connection_pool.py:256\u001b[0m, in \u001b[0;36mAsyncConnectionPool.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mAsyncIterable)\n",
      "File \u001b[0;32m~/Documents/open_deep_research/.venv/lib/python3.11/site-packages/httpcore/_async/connection_pool.py:236\u001b[0m, in \u001b[0;36mAsyncConnectionPool.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m connection\u001b[38;5;241m.\u001b[39mhandle_async_request(\n\u001b[1;32m    237\u001b[0m         pool_request\u001b[38;5;241m.\u001b[39mrequest\n\u001b[1;32m    238\u001b[0m     )\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/Documents/open_deep_research/.venv/lib/python3.11/site-packages/httpcore/_async/connection.py:103\u001b[0m, in \u001b[0;36mAsyncHTTPConnection.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_async_request(request)\n",
      "File \u001b[0;32m~/Documents/open_deep_research/.venv/lib/python3.11/site-packages/httpcore/_async/http11.py:136\u001b[0m, in \u001b[0;36mAsyncHTTP11Connection.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/Documents/open_deep_research/.venv/lib/python3.11/site-packages/httpcore/_async/http11.py:106\u001b[0m, in \u001b[0;36mAsyncHTTP11Connection.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/Documents/open_deep_research/.venv/lib/python3.11/site-packages/httpcore/_async/http11.py:177\u001b[0m, in \u001b[0;36mAsyncHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_event(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/open_deep_research/.venv/lib/python3.11/site-packages/httpcore/_async/http11.py:217\u001b[0m, in \u001b[0;36mAsyncHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\u001b[38;5;241m.\u001b[39mread(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mREAD_NUM_BYTES, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m    219\u001b[0m     )\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/Documents/open_deep_research/.venv/lib/python3.11/site-packages/httpcore/_backends/anyio.py:35\u001b[0m, in \u001b[0;36mAnyIOStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m anyio\u001b[38;5;241m.\u001b[39mfail_after(timeout):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 35\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream\u001b[38;5;241m.\u001b[39mreceive(max_bytes\u001b[38;5;241m=\u001b[39mmax_bytes)\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m anyio\u001b[38;5;241m.\u001b[39mEndOfStream:  \u001b[38;5;66;03m# pragma: nocover\u001b[39;00m\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Documents/open_deep_research/.venv/lib/python3.11/site-packages/anyio/streams/tls.py:204\u001b[0m, in \u001b[0;36mTLSStream.receive\u001b[0;34m(self, max_bytes)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreceive\u001b[39m(\u001b[38;5;28mself\u001b[39m, max_bytes: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m65536\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbytes\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_sslobject_method(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ssl_object\u001b[38;5;241m.\u001b[39mread, max_bytes)\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[1;32m    206\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m EndOfStream\n",
      "File \u001b[0;32m~/Documents/open_deep_research/.venv/lib/python3.11/site-packages/anyio/streams/tls.py:147\u001b[0m, in \u001b[0;36mTLSStream._call_sslobject_method\u001b[0;34m(self, func, *args)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_bio\u001b[38;5;241m.\u001b[39mpending:\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransport_stream\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_bio\u001b[38;5;241m.\u001b[39mread())\n\u001b[0;32m--> 147\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransport_stream\u001b[38;5;241m.\u001b[39mreceive()\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EndOfStream:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_bio\u001b[38;5;241m.\u001b[39mwrite_eof()\n",
      "File \u001b[0;32m~/Documents/open_deep_research/.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py:1246\u001b[0m, in \u001b[0;36mSocketStream.receive\u001b[0;34m(self, max_bytes)\u001b[0m\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1241\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_protocol\u001b[38;5;241m.\u001b[39mread_event\u001b[38;5;241m.\u001b[39mis_set()\n\u001b[1;32m   1242\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mis_closing()\n\u001b[1;32m   1243\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_protocol\u001b[38;5;241m.\u001b[39mis_at_eof\n\u001b[1;32m   1244\u001b[0m ):\n\u001b[1;32m   1245\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mresume_reading()\n\u001b[0;32m-> 1246\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_protocol\u001b[38;5;241m.\u001b[39mread_event\u001b[38;5;241m.\u001b[39mwait()\n\u001b[1;32m   1247\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mpause_reading()\n\u001b[1;32m   1248\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/locks.py:213\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_waiters\u001b[38;5;241m.\u001b[39mappend(fut)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 213\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import uuid \n",
    "\n",
    "# Fast config with DeepSeek-R1-Distill-Llama-70B\n",
    "# thread = {\"configurable\": {\"thread_id\": str(uuid.uuid4()),\n",
    "#                            \"search_api\": \"tavily\",\n",
    "#                            \"planner_provider\": \"groq\",\n",
    "#                            \"max_search_depth\": 1,\n",
    "#                            \"planner_model\": \"deepseek-r1-distill-llama-70b\"}}\n",
    "\n",
    "# Fast config with o3-mini\n",
    "thread = {\"configurable\": {\"thread_id\": str(uuid.uuid4()),\n",
    "                           \"search_api\": \"tavily\",\n",
    "                           \"planner_provider\": \"openai\",\n",
    "                           \"max_search_depth\": 1,\n",
    "                           \"planner_model\": \"o3-mini\"}}\n",
    "\n",
    "# Slow config, more in depth\n",
    "# thread = {\"configurable\": {\"thread_id\": str(uuid.uuid4()),\n",
    "#                            \"search_api\": \"perplexity\",\n",
    "#                            \"planner_provider\": \"openai\",\n",
    "#                            \"max_search_depth\": 2,\n",
    "#                            \"planner_model\": \"o3-mini\"}}\n",
    "\n",
    "# Create a topic\n",
    "topic = \"Overview of the AI inference market with focus on Fireworks, Together.ai, Groq\"\n",
    "\n",
    "# Run the graph until the interruption\n",
    "async for event in graph.astream({\"topic\":topic,}, thread, stream_mode=\"updates\"):\n",
    "    print(event)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass feedback to update the report plan  \n",
    "async for event in graph.astream(Command(resume=\"Include a revenue estimate (ARR) in the sections focused on Groq, Together.ai, and Fireworks\"), thread, stream_mode=\"updates\"):\n",
    "    print(event)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass True to approve the report plan \n",
    "async for event in graph.astream(Command(resume=True), thread, stream_mode=\"updates\"):\n",
    "    print(event)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# AI Inference Market and Key Players Overview\n",
       "\n",
       "The AI inference market is experiencing explosive growth, projected to expand from $24.6 billion in 2024 to $133.2 billion by 2034. This transformation is being driven by innovative companies developing breakthrough optimization technologies that dramatically improve performance while reducing costs. Among these pioneers, Fireworks AI has demonstrated enterprise-grade reliability by processing 140 billion tokens daily, while Together.ai has achieved 4x faster decoding throughput than traditional solutions. Groq's Language Processing Unit (LPU) has emerged as a particularly disruptive force, offering competitive pricing from $0.05 to $0.99 per million tokens while securing a $2.8 billion valuation.\n",
       "\n",
       "## Key Players Comparison\n",
       "\n",
       "| Feature | Fireworks AI | Together.ai | Groq |\n",
       "|---------|-------------|-------------|------|\n",
       "| Daily Processing | 140B tokens | 400 tokens/sec | Not disclosed |\n",
       "| Pricing Range | $0.10-$1.20/M tokens | Custom pricing | $0.05-$0.99/M tokens |\n",
       "| Key Innovation | Parameter-based pricing | FlashAttention-3 | Language Processing Unit |\n",
       "| Enterprise Users | Uber, DoorDash | Salesforce, Washington Post | Hunch AI, aiXplain |\n",
       "| Valuation | $552M | $100M ARR | $2.8B |\n",
       "\n",
       "These players are reshaping the inference landscape through distinct approaches to optimization and pricing, with each targeting different segments of the rapidly expanding market. Their continued innovation suggests further disruption in the AI infrastructure space.\n",
       "\n",
       "## Global AI Inference Market Analysis\n",
       "\n",
       "**The AI inference market is projected to grow from $24.6 billion in 2024 to $133.2 billion by 2034, driven by breakthrough optimization technologies that are dramatically improving performance while reducing costs.** Cloud deployment currently dominates with 55% market share, though on-premises solutions are gaining traction for latency-sensitive and security-focused applications.\n",
       "\n",
       "NVIDIA maintains market leadership with approximately 80% share of AI chips, while competitors like AMD, Intel, and cloud providers are investing heavily in specialized inference solutions. Recent advances in speculative decoding and compilation techniques have enabled up to 2x higher throughput at 50% lower costs for popular models like Llama and Mixtral.\n",
       "\n",
       "Key barriers to adoption include:\n",
       "- High infrastructure costs and unclear ROI\n",
       "- Data quality and quantity challenges\n",
       "- Integration complexity with existing systems\n",
       "- Skills gaps in AI/ML expertise\n",
       "- Privacy and regulatory concerns\n",
       "\n",
       "North America leads regional adoption with 38% market share, particularly in financial services and healthcare verticals. Microsoft's implementation of NVIDIA inference solutions for Copilot demonstrates the technology's enterprise readiness.\n",
       "\n",
       "### Sources\n",
       "- Restack AI Hardware Analysis 2024: https://www.restack.io/p/hardware-innovations-for-ai-technologies-answer-leading-ai-hardware-companies-2024\n",
       "- NVIDIA Developer Blog: https://developer.nvidia.com/blog/optimize-ai-inference-performance-with-nvidia-full-stack-solutions/\n",
       "- Market.us AI Inference Report: https://scoop.market.us/ai-inference-server-market-news/\n",
       "\n",
       "## Fireworks AI Technical Analysis\n",
       "\n",
       "**Fireworks AI combines an innovative pricing model with proven enterprise performance, demonstrated by processing 140 billion tokens daily with 99.99% API uptime across 12,000 users.** Their tiered pricing structure scales with usage, starting at $0.10 per million tokens for small models and reaching $1.20 per million tokens for large MoE architectures.\n",
       "\n",
       "The platform offers specialized pricing for different modalities:\n",
       "- Text generation with parameter-based pricing ($0.10-$1.20/M tokens)\n",
       "- Image generation at $0.00013 per step\n",
       "- Speech-to-text processing from $0.0009 per audio minute\n",
       "- On-demand GPU deployments ranging from $2.90 to $9.99 per hour\n",
       "\n",
       "A notable implementation at Sourcegraph showcases the platform's capabilities, where StarCoder deployment doubled code completion acceptance rates while cutting backend latency by 50%. The company's recent $52M Series B funding values it at $552M, with Forbes estimating 2023 revenue at $3M.\n",
       "\n",
       "Enterprise customers including Uber, DoorDash, and Upwork have adopted Fireworks AI's infrastructure, citing lower costs and reduced latency compared to alternatives. The platform's spending limits increase with usage history, from $50/month to custom enterprise tiers exceeding $50,000/month.\n",
       "\n",
       "### Sources\n",
       "- Fireworks AI Blog Spring Update: https://fireworks.ai/blog/spring-update-faster-models-dedicated-deployments-postpaid-pricing\n",
       "- AWS Case Study: https://aws.amazon.com/solutions/case-studies/fireworks-ai-case-study/\n",
       "- Funding News: https://www.pymnts.com/news/investment-tracker/2024/fireworks-ai-valued-552-million-dollars-after-new-funding-round/\n",
       "\n",
       "## Together.ai's Inference Stack Analysis\n",
       "\n",
       "**Together.ai has revolutionized LLM inference by achieving 4x faster decoding throughput than open-source vLLM through an integrated approach combining hardware optimization and algorithmic innovations.** Their Inference Engine 2.0 demonstrates superior performance by processing over 400 tokens per second on Meta's Llama 3 8B model.\n",
       "\n",
       "The technical foundation relies on four key innovations:\n",
       "- FlashAttention-3 optimization achieving 75% GPU utilization\n",
       "- Custom-built draft models trained beyond 10x Chinchilla optimal\n",
       "- Advanced speculative decoding combining Medusa and Sequoia techniques\n",
       "- Quality-preserving quantization matching FP16 precision\n",
       "\n",
       "A notable case study demonstrates their efficiency at scale: using just two A100 GPUs, Together Lite outperforms vLLM running on eight H100 GPUs by 30% in common inference scenarios. This translates to a 12x cost reduction compared to standard deployments.\n",
       "\n",
       "The Enterprise Platform builds on these innovations while maintaining SOC 2, GDPR, and HIPAA compliance. Major enterprises including Salesforce and The Washington Post have validated its performance in production environments, contributing to Together.ai reaching $100M ARR within 10 months of launch.\n",
       "\n",
       "### Sources\n",
       "- Together Inference Engine 2.0 Announcement: https://www.together.ai/blog/together-inference-engine-2\n",
       "- Enterprise Platform Security: https://www.togetherplatform.com/security-compliance\n",
       "- Speculative Decoding Implementation: https://www.together.ai/blog/speculative-decoding-for-high-throughput-long-context-inference\n",
       "\n",
       "## Groq's Inference Engine Performance and Market Traction\n",
       "\n",
       "**Groq's Language Processing Unit (LPU) has demonstrated unprecedented inference speeds while achieving significant market validation, with an estimated $3.4 million revenue in 2023 and a $2.8 billion valuation following their August 2024 Series D round.**\n",
       "\n",
       "The LPU's competitive pricing structure ranges from $0.05 to $0.99 per million tokens, depending on model size and input/output requirements. For example, their Llama 3.3 70B implementation charges $0.59 per million input tokens and $0.79 per million output tokens, positioning them favorably against cloud competitors.\n",
       "\n",
       "Developer adoption has been robust, with notable implementations including:\n",
       "- Hunch AI Workspace for rapid prototyping\n",
       "- aiXplain's real-time inference solutions\n",
       "- Argonne National Laboratory's research applications\n",
       "- Embodied's Moxie education robot\n",
       "\n",
       "The platform offers an OpenAI-compatible API supporting multiple models including Llama 3.3, Mixtral 8x7b, and Gemma 2. Integration options include LangChain compatibility and Retrieval Augmented Generation capabilities, enabling developers to incorporate proprietary data into their applications.\n",
       "\n",
       "### Sources\n",
       "- Sacra Company Analysis: https://sacra.com/c/groq/\n",
       "- Groq Pricing Documentation: https://groq.com/pricing/\n",
       "- ChipStrat Analysis: https://www.chipstrat.com/p/the-rise-of-groq-slow-then-fast\n",
       "- Groq API Documentation: https://distilabel.argilla.io/1.2.1/api/llm/groq/\n",
       "\n",
       "## Market and Provider Analysis Summary\n",
       "\n",
       "The AI inference market is experiencing rapid growth, projected to reach $133.2 billion by 2034, with cloud deployment currently dominating at 55% market share. Among emerging providers, Fireworks AI, Together.ai, and Groq demonstrate distinct competitive advantages in performance and pricing strategies.\n",
       "\n",
       "| Provider | Key Differentiator | Performance Metric | Revenue/Valuation |\n",
       "|----------|-------------------|-------------------|-------------------|\n",
       "| Fireworks AI | Enterprise-grade reliability | 140B tokens/day, 99.99% uptime | $3M (2023), $552M valuation |\n",
       "| Together.ai | Advanced optimization stack | 4x faster than vLLM, 400 tokens/sec | $100M ARR |\n",
       "| Groq | Custom LPU architecture | Industry-leading latency | $3.4M (2023), $2.8B valuation |\n",
       "\n",
       "These providers are addressing key market barriers through innovative pricing models, ranging from $0.05 to $1.20 per million tokens, while delivering specialized solutions for different modalities and use cases. Their success in attracting major enterprise customers suggests growing market maturity, though NVIDIA's 80% chip market share indicates continued infrastructure dependencies."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "final_state = graph.get_state(thread)\n",
    "report = final_state.values.get('final_report')\n",
    "Markdown(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "report-maistro-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
